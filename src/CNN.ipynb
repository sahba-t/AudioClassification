{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Handle Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def read_audio(f_names: list, path: str):\n",
    "    data   = [[]] * len(f_names)  # (data, samp_rate)\n",
    "    srs     = [0] * len(f_names)\n",
    "    labels = [0] * len(f_names)\n",
    "\n",
    "    for i in range(len(f_names)):\n",
    "        x, sr = librosa.load(path + f_names[i], sr=None, mono=True)\n",
    "        data[i] = x\n",
    "        srs[i] = sr\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('i=', i, '\\t num points:', x.shape, 'samp_rate:', sr)\n",
    "    print(\"Finished reading\", len(data), \"audio files from\", path,)\n",
    "    return data, srs\n",
    "\n",
    "def read_labels(f_names: list):\n",
    "    labels = np.zeros(len(f_names))\n",
    "    y_df = pd.read_csv('../res/train.csv', header=0, dtype={'new_id':str, 'genre':np.int16})\n",
    "    y_df = y_df.set_index('new_id')\n",
    "    for i in range(len(f_names)):\n",
    "        labels[i] = y_df.loc[f_names[i][:-4]].genre\n",
    "    return labels\n",
    "\n",
    "def read_spectrogram(path: str, f_names: list):\n",
    "    img_data = np.zeros(shape=(len(f_names), expected_spectro_shape[0], expected_spectro_shape[1]))\n",
    "    for i in range(len(f_names)):\n",
    "        img_data[i] = io.imread(path + f_names[i][:-3] + 'png')\n",
    "        if expected_spectro_shape != img_data[i].shape:\n",
    "            print(\"index:\", i, \"has shape\", img_data[i].shape)\n",
    "    print(\"Spectrogram from\", path, \"read in! Shape is:\", img_data.shape)\n",
    "    return img_data\n",
    "\n",
    "def save_audio_as_spectrogram(data: list, srs: list, f_names: list, path: str):\n",
    "    def scale_minmax(x_audio, min=0.0, max=1.0):\n",
    "        x_audio_std = (x_audio - x_audio.min()) / (x_audio.max() - x_audio.min())\n",
    "        x_audio_scaled = x_audio_std * (max - min) + min\n",
    "        return x_audio_scaled\n",
    "    hop_length = 512  # samples per time sample\n",
    "    time_steps= 2550  # width of data\n",
    "    n_mels = 128  # height\n",
    "\n",
    "    for i in range(len(f_names)):\n",
    "        data[i] = data[i][:time_steps * hop_length]\n",
    "        mels = librosa.feature.melspectrogram(y=data[i], sr=srs[i],\n",
    "                                              n_mels=n_mels,\n",
    "                                              n_fft=hop_length*2, hop_length=hop_length)\n",
    "        mels = np.log(mels + 1e-9) # add small number to avoid log(0)\n",
    "\n",
    "        # min-max scale to fit inside 8-bit range\n",
    "        img = scale_minmax(mels, 0, 255).astype(np.uint8)\n",
    "        img = np.flip(img, axis=0) # put low frequencies at the bottom in image\n",
    "        img = 255 - img # invert. make black==more energy\n",
    "\n",
    "        # save as PNG\n",
    "        io.imsave(path + f_names[i][:-4] + '.png', img)\n",
    "    print(\"Finished! Images saved to\", path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set Path Variables\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_wav_path = '../res/wav/train/'\n",
    "test_wav_path = '../res/wav/test/'\n",
    "train_spectro_path = '../res/spectrogram/train/'\n",
    "test_spectro_path = '../res/spectrogram/test/'\n",
    "\n",
    "train_wav_names = os.listdir(train_wav_path)\n",
    "test_wav_names = os.listdir(test_wav_path)\n",
    "train_spectro_names = os.listdir(train_spectro_path)\n",
    "test_spectro_names = os.listdir(test_spectro_path)\n",
    "\n",
    "expected_spectro_shape = (128, 2551)\n",
    "num_classes = 6\n",
    "\n",
    "print(\"num train wavs:\", len(train_wav_names))\n",
    "print(\"num test wavs:\", len(test_wav_names))\n",
    "print(\"num train spectros:\", len(train_spectro_names))\n",
    "print(\"num test spectros:\", len(test_spectro_names))\n",
    "print(\"expected_spectro_shape:\", expected_spectro_shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read Training .wav Files and Save as Spectrograms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Number of train .wav files in audio folder:\", len(train_wav_names))\n",
    "training_wav, training_srs = read_audio(train_wav_names, train_wav_path)\n",
    "\n",
    "save_audio_as_spectrogram(training_wav,\n",
    "                          training_srs,\n",
    "                          train_wav_names,\n",
    "                          train_spectro_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read Testing .wav Files and Save as Spectrograms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Number of train .wav files in audio folder:\", len(test_wav_names))\n",
    "testing_wav, testing_srs = read_audio(test_wav_names, test_wav_path)\n",
    "\n",
    "save_audio_as_spectrogram(testing_wav,\n",
    "                          testing_srs,\n",
    "                          test_wav_names,\n",
    "                          test_spectro_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read Training & Testing Spectrogram PNGs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_x = read_spectrogram(train_spectro_path, train_spectro_names)\n",
    "training_labels = read_labels(train_wav_names)\n",
    "testing_x = read_spectrogram(test_spectro_path, test_spectro_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TF Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = keras.models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=3, strides=1),\n",
    "    # layers.BatchNormalization(),\n",
    "    # layers.MaxPool2D(pool_size=(2, 2), strides=1),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(num_classes)\n",
    "])\n",
    "model.compile()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TF Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "amount_train_x = len(training_x)//2\n",
    "# train_set_x = training_x[]\n",
    "# train_set_y = training_labels[:amount_train_x].copy()\n",
    "\n",
    "eval_set_x = training_x[amount_train_x:]\n",
    "eval_set_y = training_labels[amount_train_x:]\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=loss_fn,\n",
    "#               metrics=['accuracy'])\n",
    "model.fit(training_x, training_labels, epochs=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TF Training Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(train_set_x, train_set_y, epochs=10, validation_data=(eval_set_x, eval_set_y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## File Writing"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}