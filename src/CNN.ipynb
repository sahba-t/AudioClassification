{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from skimage import io\n",
    "from sklearn import metrics\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_audio(f_names: list, path: str):\n",
    "    data   = [[]] * len(f_names)  # (data, samp_rate)\n",
    "    srs     = [0] * len(f_names)\n",
    "    labels = [0] * len(f_names)\n",
    "\n",
    "    for i in range(len(f_names)):\n",
    "        x, sr = librosa.load(path + f_names[i], sr=None, mono=True)\n",
    "        data[i] = x\n",
    "        srs[i] = sr\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('i=', i, '\\t num points:', x.shape, 'samp_rate:', sr)\n",
    "    print(\"Finished reading\", len(data), \"audio files from\", path,)\n",
    "    return data, srs\n",
    "\n",
    "def read_labels(f_names: list):\n",
    "    labels = np.zeros(len(f_names))\n",
    "    y_df = pd.read_csv('../res/train.csv', header=0, dtype={'new_id': str, 'genre': np.int16})\n",
    "    y_df = y_df.set_index('new_id')\n",
    "    for i in range(len(f_names)):\n",
    "        labels[i] = y_df.loc[f_names[i][:-4]].genre\n",
    "    print(\"Finished reading\", len(labels), 'labels')\n",
    "    return labels\n",
    "\n",
    "def read_spectrogram(path: str, f_names: list):\n",
    "    img_data = np.zeros(shape=(len(f_names), expected_spectro_shape[0], expected_spectro_shape[1]))\n",
    "    for i in range(len(f_names)):\n",
    "        spectro = io.imread(path + f_names[i][:-3] + 'png')\n",
    "\n",
    "        if spectro.shape[1] > expected_spectro_shape[1]:\n",
    "            spectro = spectro[:, :(expected_spectro_shape[1] - spectro.shape[1])]\n",
    "        elif spectro.shape[1] < expected_spectro_shape[1]:\n",
    "            padding_matrix_shape = (expected_spectro_shape[0], expected_spectro_shape[1] - spectro.shape[1])\n",
    "            spectro = np.hstack((spectro, np.zeros(padding_matrix_shape)))\n",
    "\n",
    "        img_data[i] = spectro\n",
    "        if expected_spectro_shape != img_data[i].shape:\n",
    "            print(\"index:\", i, \"has shape\", img_data[i].shape)\n",
    "    print(\"Spectrogram from\", path, \"read in! Shape is:\", img_data.shape)\n",
    "    return img_data\n",
    "\n",
    "def save_audio_as_spectrogram(data: list, srs: list, f_names: list, path: str):\n",
    "    def scale_minmax(x_audio, min=0.0, max=1.0):\n",
    "        x_audio_std = (x_audio - x_audio.min()) / (x_audio.max() - x_audio.min())\n",
    "        x_audio_scaled = x_audio_std * (max - min) + min\n",
    "        return x_audio_scaled\n",
    "    hop_length = 512  # samples per time sample\n",
    "    time_steps= 2550  # width of data\n",
    "    n_mels = 128  # height\n",
    "\n",
    "    for i in range(len(f_names)):\n",
    "        data[i] = data[i][:time_steps * hop_length]\n",
    "        mels = librosa.feature.melspectrogram(y=data[i], sr=srs[i],\n",
    "                                              n_mels=n_mels,\n",
    "                                              n_fft=hop_length*2, hop_length=hop_length)\n",
    "        mels = np.log(mels + 1e-9) # add small number to avoid log(0)\n",
    "\n",
    "        # min-max scale to fit inside 8-bit range\n",
    "        img = scale_minmax(mels, 0, 255).astype(np.uint8)\n",
    "        img = np.flip(img, axis=0) # put low frequencies at the bottom in image\n",
    "        img = 255 - img # invert. make black==more energy\n",
    "\n",
    "        # save as PNG\n",
    "        io.imsave(path + f_names[i][:-4] + '.png', img)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('i=', i, '\\t img shape:', img.shape)\n",
    "    print(\"Finished! Images saved to\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Path Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train wavs: 2400\n",
      "num test wavs: 1202\n",
      "num train spectros: 2400\n",
      "num test spectros: 1200\n",
      "expected_spectro_shape: (128, 2551)\n"
     ]
    }
   ],
   "source": [
    "train_wav_path = '../res/wav/train/'\n",
    "test_wav_path = '../res/wav/test/'\n",
    "train_spectro_path = '../res/spectrogram/train/'\n",
    "test_spectro_path = '../res/spectrogram/test/'\n",
    "\n",
    "train_wav_names = os.listdir(train_wav_path)\n",
    "test_wav_names = os.listdir(test_wav_path)\n",
    "train_spectro_names = os.listdir(train_spectro_path)\n",
    "test_spectro_names = os.listdir(test_spectro_path)\n",
    "\n",
    "expected_spectro_shape = (128, 2551)\n",
    "num_classes = 6\n",
    "\n",
    "img_rows = expected_spectro_shape[0]\n",
    "img_cols = expected_spectro_shape[1]\n",
    "\n",
    "print(\"num train wavs:\", len(train_wav_names))\n",
    "print(\"num test wavs:\", len(test_wav_names))\n",
    "print(\"num train spectros:\", len(train_spectro_names))\n",
    "print(\"num test spectros:\", len(test_spectro_names))\n",
    "print(\"expected_spectro_shape:\", expected_spectro_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Training .wav Files and Save as Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train .wav files in audio folder: 2400\n",
      "i= 0 \t num points: (1321967,) samp_rate: 44100\n",
      "i= 100 \t num points: (1321967,) samp_rate: 44100\n",
      "i= 200 \t num points: (1321967,) samp_rate: 44100\n",
      "i= 300 \t num points: (1323119,) samp_rate: 44100\n",
      "i= 400 \t num points: (1321967,) samp_rate: 44100\n",
      "i= 500 \t num points: (1321967,) samp_rate: 44100\n",
      "i= 600 \t num points: (1323119,) samp_rate: 44100\n",
      "i= 700 \t num points: (1321967,) samp_rate: 44100\n",
      "i= 800 \t num points: (1321967,) samp_rate: 44100\n",
      "i= 900 \t num points: (1323119,) samp_rate: 44100\n",
      "i= 1000 \t num points: (1321967,) samp_rate: 44100\n",
      "i= 1100 \t num points: (1321967,) samp_rate: 44100\n",
      "i= 1200 \t num points: (1321967,) samp_rate: 44100\n",
      "i= 1300 \t num points: (1323119,) samp_rate: 44100\n",
      "i= 1400 \t num points: (1323119,) samp_rate: 44100\n",
      "i= 1500 \t num points: (1439471,) samp_rate: 48000\n",
      "i= 1600 \t num points: (1323119,) samp_rate: 44100\n",
      "i= 1700 \t num points: (1321967,) samp_rate: 44100\n",
      "i= 1800 \t num points: (1323119,) samp_rate: 44100\n",
      "i= 1900 \t num points: (1321967,) samp_rate: 44100\n",
      "i= 2000 \t num points: (1321967,) samp_rate: 44100\n",
      "i= 2100 \t num points: (1323119,) samp_rate: 44100\n",
      "i= 2200 \t num points: (1321967,) samp_rate: 44100\n",
      "i= 2300 \t num points: (1323119,) samp_rate: 44100\n",
      "Finished reading 2400 audio files from ../res/wav/train/\n",
      "Finished! Images saved to ../res/spectrogram/train/\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train .wav files in audio folder:\", len(train_wav_names))\n",
    "training_wav, training_srs = read_audio(train_wav_names, train_wav_path)\n",
    "\n",
    "save_audio_as_spectrogram(training_wav,\n",
    "                          training_srs,\n",
    "                          train_wav_names,\n",
    "                          train_spectro_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Testing .wav Files and Save as Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Number of train .wav files in audio folder:\", len(test_wav_names))\n",
    "testing_wav, testing_srs = read_audio(test_wav_names, test_wav_path)\n",
    "\n",
    "save_audio_as_spectrogram(testing_wav,\n",
    "                          testing_srs,\n",
    "                          test_wav_names,\n",
    "                          test_spectro_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Model & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_CI(score, sample_size):\n",
    "    print('CI = %.2f' % (math.sqrt(score * (1 - score) / sample_size) * 100))\n",
    "\n",
    "def format_data(data):\n",
    "    img_rows = expected_spectro_shape[0]\n",
    "    img_cols = expected_spectro_shape[1]\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        data_x = data.reshape(data.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        data_x = data.reshape(data.shape[0], img_rows, img_cols, 1)\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "    return data_x, input_shape\n",
    "\n",
    "def plot_conf_matrix(acc, conf_array):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(conf_array)\n",
    "    labels = \"Rock,Pop,Folk,Instr,Elec,HH\".split(',')\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(len(labels)))\n",
    "    ax.set_yticks(np.arange(len(labels)))\n",
    "    # ... and label them with the respective list entries\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            ax.text(j, i, \"%.2f\" % conf_array[i, j], ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "    ax.set_title(\"The Confusion Matrix\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"../res/confMat/confMat_cnn_acc\" + str(acc) + \".png\", bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()\n",
    "\n",
    "def create_1D_CNN(input_shape):\n",
    "    model = keras.models.Sequential()\n",
    "    # model.add(layers.Conv1D(filters=4, kernel_size=8, activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.Conv1D(filters=8, kernel_size=16, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "\n",
    "    model.add(layers.Conv1D(filters=8, kernel_size=16, activation='relu'))\n",
    "    # model.add(layers.Conv1D(filters=8, kernel_size=32, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=.09),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_and_write_file():\n",
    "    training_x = read_spectrogram(train_spectro_path, train_spectro_names)\n",
    "    training_labels = read_labels(train_spectro_names)\n",
    "\n",
    "    shuffle_training_x_labs = list(zip(training_x, training_labels))\n",
    "    shuffle(shuffle_training_x_labs)\n",
    "\n",
    "    training_x = np.array([x for x, _ in shuffle_training_x_labs])\n",
    "    training_labels = np.array([l for _, l in shuffle_training_x_labs])\n",
    "\n",
    "    train_size = int(len(training_x) * .85)\n",
    "\n",
    "    train_set_x = training_x[:train_size]\n",
    "    train_set_y = training_labels[:train_size]\n",
    "    eval_set_x = training_x[train_size:]\n",
    "    eval_set_y = training_labels[train_size:]\n",
    "    print(\"\\n\\n\")\n",
    "    print(training_x.shape)\n",
    "    print(train_set_y.shape)\n",
    "    print(eval_set_y.shape)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # model = create_CNN_1d(input_shape=(img_rows, img_cols)) # Sahba's\n",
    "    model = create_1D_CNN(input_shape=(img_rows, img_cols))  # Mauricio's\n",
    "    model.fit(train_set_x, train_set_y,\n",
    "              epochs=50,\n",
    "              # batch_size=50,\n",
    "              shuffle=True,  # @TODO make true when you fine a high acc on current architecture\n",
    "              verbose=1,\n",
    "              validation_data=(eval_set_x, eval_set_y),\n",
    "              use_multiprocessing=True)\n",
    "\n",
    "    model.summary()\n",
    "    score = model.evaluate(training_x[train_size:], eval_set_y, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    predictions = model.predict(eval_set_x)\n",
    "    matrix = metrics.confusion_matrix(eval_set_y, predictions.argmax(axis=1))\n",
    "    print(matrix)\n",
    "    plot_conf_matrix(score[1], matrix)\n",
    "    calc_CI(score=score[1], sample_size=len(eval_set_y))\n",
    "\n",
    "    if score[1] > .6:\n",
    "        testing_x = read_spectrogram(test_spectro_path, test_spectro_names)\n",
    "        predictions = model.predict(testing_x)\n",
    "        with open('../results/CNN_' + str(score[1]) + '.csv', 'w') as csv_stream:\n",
    "            csv_stream.write('id,genre\\n')\n",
    "            for r in range(predictions.shape[0]):\n",
    "                predicted_genre = np.argmax(predictions[r, :])\n",
    "                file_label = test_spectro_names[r][:-4]\n",
    "                csv_stream.write(f\"{file_label},{predicted_genre}\\n\")\n",
    "        print('File written to:', '../results/CNN_' + str(score[1]) + '.csv')\n",
    "\n",
    "train_and_write_file()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}